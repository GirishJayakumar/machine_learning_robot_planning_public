[environment]
agent_names = ['agent1', 'agent2']
steps_per_action = 1

[agent1]
type = simulated_robot
data_type = numpy
start_state = [0.0, 0.0, 0.0, 0.0, 0.0]
cost_evaluator = my_cost_evaluator1
dynamics = my_dynamics1
observer = my_observer1
steps_per_action = 1

[my_dynamics1]
type = bicycle_dynamics
mass = 1.0
cog_pos = 0.5
car_length = 1
delta_t = 0.2

[my_cost_evaluator1]
type = quadratic_cost
collision_cost = 1000
goal_cost = -5000
Q = [[1.0, 0.0, 0.0, 0.0, 0.0],[0.0, 1.0, 0.0, 0.0, 0.0],[0.0, 0.0, 1.0, 0.0, 0.0],[0.0, 0.0, 0.0, 1.0, 0.0],[0.0, 0.0, 0.0, 0.0, 1.0]]
R = [[1.0, 0.0],[0.0, 1.0]]
goal_checker = my_goal_checker1
collision_checker = my_collision_checker1

[my_goal_checker1]
type = state_space_goal_checker
goal_state = [10.0, 0.0, 0.0, 0.0, 5.0]
goal_radius = 1.5

[my_collision_checker1]
type = point_collision_checker
obstacles = [[3.0, 0.0], [7.0, 0.0]]
obstacles_radius = [0.0, 0.0]
kinematics = my_kinematics1

[my_kinematics1]
type = point_kinematics
radius = 1

[my_observer1]
type = full_state_observer


[agent2]
type = simulated_robot
data_type = numpy
start_state = [10.0, 0.0, 0.0, 0.0, 0.0]
cost_evaluator = my_cost_evaluator2
dynamics = my_dynamics2
observer = my_observer2
steps_per_action = 1

[my_dynamics2]
type = bicycle_dynamics
mass = 1.0
cog_pos = 0.5
car_length = 1
delta_t = 0.2

[my_cost_evaluator2]
type = quadratic_cost
collision_cost = 1000
goal_cost = -5000
Q = [[1.0, 0.0, 0.0, 0.0, 0.0],[0.0, 1.0, 0.0, 0.0, 0.0],[0.0, 0.0, 1.0, 0.0, 0.0],[0.0, 0.0, 0.0, 1.0, 0.0],[0.0, 0.0, 0.0, 0.0, 1.0]]
R = [[1.0, 0.0],[0.0, 1.0]]
goal_checker = my_goal_checker2
collision_checker = my_collision_checker2

[my_goal_checker2]
type = state_space_goal_checker
goal_state = [0.0, 0.0, 0.0, 0.0, -5.0]
goal_radius = 1.5

[my_collision_checker2]
type = point_collision_checker
obstacles = [[3.0, 0.0], [7.0, 0.0]]
obstacles_radius = [0.0, 0.0]
kinematics = my_kinematics2

[my_kinematics2]
type = point_kinematics
radius = 1

[my_observer2]
type = full_state_observer












